{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "# Define the function to save processed data\n",
    "def save_processed_data(data, label, save_path):\n",
    "    np.savez(save_path, data=data, label=label)\n",
    "\n",
    "path_to_the_dataset = 'donateacry_corpus_cleaned_and_updated_data'\n",
    "\n",
    "# List of subfolders\n",
    "subfolders = ['belly_pain', 'burping', 'discomfort', 'hungry', 'tired']\n",
    "\n",
    "# Function to save the processed data\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    folder_path = os.path.join(path_to_the_dataset, subfolder)\n",
    "\n",
    "    for audio_file in os.listdir(folder_path):\n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(folder_path, audio_file)\n",
    "\n",
    "            # Load the audio file using Librosa\n",
    "            audio, sr = librosa.load(audio_path)\n",
    "\n",
    "            # Compute the spectrogram\n",
    "            spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128, fmax=8000)\n",
    "            spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "\n",
    "            # Save the spectrogram data\n",
    "            save_path_spectrogram = os.path.join(folder_path, f\"{os.path.splitext(audio_file)[0]}_spectrogram.npz\")\n",
    "            save_processed_data(spectrogram_db, subfolder, save_path_spectrogram)\n",
    "\n",
    "            # Compute the MFCCs\n",
    "            mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "\n",
    "            # Save the MFCC data\n",
    "            save_path_mfcc = os.path.join(folder_path, f\"{os.path.splitext(audio_file)[0]}_mfcc.npz\")\n",
    "            save_processed_data(mfccs, subfolder, save_path_mfcc)\n",
    "\n",
    "# Display a sample spectrogram and MFCC\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Display a sample spectrogram\n",
    "plt.subplot(2, 1, 1)\n",
    "librosa.display.specshow(spectrogram_db, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Sample Spectrogram')\n",
    "\n",
    "# Display a sample MFCC\n",
    "plt.subplot(2, 1, 2)\n",
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('Sample MFCC')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training set: 365\n",
      "Size of the testing set: 92\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the base path of your dataset\n",
    "path_to_your_dataset = 'donateacry_corpus_cleaned_and_updated_data'\n",
    "\n",
    "# List the subfolders corresponding to each class\n",
    "subfolders = ['belly_pain', 'burping', 'discomfort', 'hungry', 'tired']\n",
    "\n",
    "# Initialize lists to store file paths and labels\n",
    "data = []    # This list will store the paths of audio files\n",
    "labels = []  # This list will store the corresponding labels (class indices)\n",
    "\n",
    "# Iterate through each subfolder\n",
    "for label, subfolder in enumerate(subfolders):\n",
    "    folder_path = os.path.join(path_to_your_dataset, subfolder)\n",
    "    \n",
    "    # Iterate through each audio file in the subfolder\n",
    "    for audio_file in os.listdir(folder_path):\n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(folder_path, audio_file)\n",
    "            data.append(audio_path)\n",
    "            labels.append(label)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the size of the training and testing sets\n",
    "print(f\"Size of the training set: {len(train_data)}\")\n",
    "print(f\"Size of the testing set: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dell\\ENSIAS\\S3\\Infant_Monitoring_Device_\\cry_analysis\\Baby_Cry_Analysis.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dell/ENSIAS/S3/Infant_Monitoring_Device_/cry_analysis/Baby_Cry_Analysis.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlibrosa\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dell/ENSIAS/S3/Infant_Monitoring_Device_/cry_analysis/Baby_Cry_Analysis.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Dell/ENSIAS/S3/Infant_Monitoring_Device_/cry_analysis/Baby_Cry_Analysis.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dell/ENSIAS/S3/Infant_Monitoring_Device_/cry_analysis/Baby_Cry_Analysis.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dell/ENSIAS/S3/Infant_Monitoring_Device_/cry_analysis/Baby_Cry_Analysis.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelEncoder\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the base path of your dataset\n",
    "path_to_your_dataset = 'donateacry_corpus_cleaned_and_updated_data'\n",
    "\n",
    "# List the subfolders corresponding to each class\n",
    "subfolders = ['belly_pain', 'burping', 'discomfort', 'hungry', 'tired']\n",
    "\n",
    "# Initialize lists to store file paths and labels\n",
    "data = []    # This list will store the paths of audio files\n",
    "labels = []  # This list will store the corresponding labels (class names)\n",
    "\n",
    "# Iterate through each subfolder\n",
    "for label, subfolder in enumerate(subfolders):\n",
    "    folder_path = os.path.join(path_to_your_dataset, subfolder)\n",
    "    \n",
    "    # Iterate through each audio file in the subfolder\n",
    "    for audio_file in os.listdir(folder_path):\n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(folder_path, audio_file)\n",
    "            data.append(audio_path)\n",
    "            labels.append(subfolder)\n",
    "\n",
    "# Convert labels to numbers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to extract audio features (spectrograms)\n",
    "def extract_features(audio_path):\n",
    "    audio, _ = librosa.load(audio_path, res_type='kaiser_fast')\n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio, sr=22050, n_mels=128, fmax=8000)\n",
    "    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    return spectrogram_db\n",
    "\n",
    "# Create training and testing sets\n",
    "X_train = [extract_features(audio_path) for audio_path in train_data]\n",
    "X_test = [extract_features(audio_path) for audio_path in test_data]\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "# Add a dimension to indicate the channel (1 for grayscale)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))\n",
    "\n",
    "# Convert labels to one-hot format\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "# Create the CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(len(subfolders), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_one_hot, epochs=10, batch_size=32, validation_data=(X_test, y_test_one_hot))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"Accuracy on the test set: {test_acc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

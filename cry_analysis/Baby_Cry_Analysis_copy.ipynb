{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Définir le chemin vers votre dataset\n",
    "path_to_your_dataset = 'donateacry_corpus_cleaned_and_updated_data'\n",
    "\n",
    "# Listez les sous-dossiers correspondant à chaque classe\n",
    "subfolders = ['belly_pain', 'burping', 'discomfort', 'hungry', 'tired']\n",
    "\n",
    "# Initialiser des listes pour stocker les chemins des fichiers audio et les étiquettes\n",
    "data = []    # Cette liste stockera les chemins des fichiers audio\n",
    "labels = []  # Cette liste stockera les étiquettes correspondantes (noms de classe)\n",
    "\n",
    "# Parcourez chaque sous-dossier\n",
    "for label, subfolder in enumerate(subfolders):\n",
    "    folder_path = os.path.join(path_to_your_dataset, subfolder)\n",
    "    \n",
    "    # Parcourez chaque fichier audio dans le sous-dossier\n",
    "    for audio_file in os.listdir(folder_path):\n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(folder_path, audio_file)\n",
    "            data.append(audio_path)\n",
    "            labels.append(subfolder)\n",
    "\n",
    "# Convertissez les étiquettes en nombres\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Divisez les données en ensembles de formation et de test (80% formation, 20% test)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fonction pour normaliser les fichiers audio\n",
    "def normalize_audio(audio_path):\n",
    "    audio, _ = librosa.load(audio_path, res_type='kaiser_fast')\n",
    "    normalized_audio = librosa.util.normalize(audio)\n",
    "    return normalized_audio\n",
    "\n",
    "# Normalisez les fichiers audio dans les ensembles de formation et de test\n",
    "train_data = [normalize_audio(audio_path) for audio_path in train_data]\n",
    "test_data = [normalize_audio(audio_path) for audio_path in test_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les caractéristiques audio (spectrogrammes)\n",
    "def extract_spectrogram(audio):\n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio, sr=22050, n_mels=128, fmax=8000)\n",
    "    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    return spectrogram_db\n",
    "\n",
    "# Créez des ensembles de formation et de test de spectrogrammes\n",
    "X_train = [extract_spectrogram(audio) for audio in train_data]\n",
    "X_test = [extract_spectrogram(audio) for audio in test_data]\n",
    "\n",
    "# Trouvez la forme minimale des spectrogrammes\n",
    "min_shape = min([spectrogram.shape[1] for spectrogram in X_train + X_test])\n",
    "\n",
    "# Fonction pour remodeler et tronquer les spectrogrammes\n",
    "def reshape_and_truncate(spectrogram, target_shape):\n",
    "    if spectrogram.shape[1] > target_shape:\n",
    "        return spectrogram[:, :target_shape]\n",
    "    else:\n",
    "        return np.pad(spectrogram, ((0, 0), (0, target_shape - spectrogram.shape[1])))\n",
    "\n",
    "# Appliquer reshape_and_truncate à tous les spectrogrammes\n",
    "X_train = [reshape_and_truncate(spectrogram, min_shape) for spectrogram in X_train]\n",
    "X_test = [reshape_and_truncate(spectrogram, min_shape) for spectrogram in X_test]\n",
    "\n",
    "# Convertir les listes en tableaux NumPy\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "12/12 [==============================] - 8s 420ms/step - loss: 880.5935 - accuracy: 0.7041 - val_loss: 1211.8361 - val_accuracy: 0.7826\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 5s 405ms/step - loss: 518.1255 - accuracy: 0.8137 - val_loss: 187.4809 - val_accuracy: 0.1196\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 4s 351ms/step - loss: 117.2665 - accuracy: 0.6904 - val_loss: 101.4800 - val_accuracy: 0.7826\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 59.0936 - accuracy: 0.7288 - val_loss: 68.2258 - val_accuracy: 0.7826\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 5s 375ms/step - loss: 20.8865 - accuracy: 0.8384 - val_loss: 15.2698 - val_accuracy: 0.2717\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 5s 383ms/step - loss: 5.2468 - accuracy: 0.8356 - val_loss: 12.6530 - val_accuracy: 0.7826\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 4s 351ms/step - loss: 2.1912 - accuracy: 0.9452 - val_loss: 9.1272 - val_accuracy: 0.7174\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 5s 408ms/step - loss: 1.0769 - accuracy: 0.9096 - val_loss: 9.6642 - val_accuracy: 0.7717\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 4s 327ms/step - loss: 0.1091 - accuracy: 0.9863 - val_loss: 8.4072 - val_accuracy: 0.7391\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 4s 321ms/step - loss: 0.0175 - accuracy: 0.9890 - val_loss: 10.5120 - val_accuracy: 0.7717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x18ee69d17d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Définissez l'architecture du modèle\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(len(subfolders), activation='softmax'))\n",
    "\n",
    "# Compilez le modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Ajoutez une dimension pour indiquer les canaux (1 pour les niveaux de gris)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "# Entraînez le modèle\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 77ms/step - loss: 7.1660 - accuracy: 0.7826\n",
      "Test Accuracy: 0.782608687877655\n",
      "3/3 [==============================] - 0s 74ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  belly_pain       0.00      0.00      0.00         4\n",
      "     burping       0.00      0.00      0.00         2\n",
      "  discomfort       0.00      0.00      0.00         7\n",
      "      hungry       0.78      1.00      0.88        72\n",
      "       tired       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.78        92\n",
      "   macro avg       0.16      0.20      0.18        92\n",
      "weighted avg       0.61      0.78      0.69        92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Évaluez le modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Faites des prédictions sur l'ensemble de test\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convertissez les prédictions en classes\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Analysez les métriques telles que la précision, le rappel, et la précision\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted_classes, target_names=subfolders))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from scipy.io import wavfile\n",
    "import shutil\n",
    "import hashlib\n",
    "\n",
    "input_folder = r\"C:\\\\Users\\Dell\\\\ENSIAS\\S3\\\\Infant_Monitoring_Device_\\\\cry_analysis\\donateacry_corpus_cleaned_and_updated_data\"  # Replace with the actual path to your input folder\n",
    "output_folder = r\"C:\\\\Users\\Dell\\\\ENSIAS\\S3\\\\Infant_Monitoring_Device_\\\\cry_analysis\\donateacry_corpus_cleaned_and_updated_data_augmentated\"  # Replace with the actual path to your output folder\n",
    "\n",
    "desired_num_audios = 10  # number of desired audios\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "crop_duration = 3  # Random cropping duration in seconds\n",
    "noise_level = 0.05  # Standard deviation for random normal distribution noise\n",
    "volume_factor_range = [0.8, 1.2]  # Range for volume adjustment\n",
    "speed_factor_range = [0.8, 1.2]  # Range for speed perturbation\n",
    "pitch_semitones_range = [-2, 2]  # Range for pitch variation\n",
    "\n",
    "# Define a set to store unique hashes of generated audio files\n",
    "generated_audio_hashes = set()\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "audio_files = os.listdir(input_folder)\n",
    "num_input_audios = len(audio_files)\n",
    "\n",
    "# Copy the original audios\n",
    "for audio_file in audio_files:\n",
    "    input_audio_path = os.path.join(input_folder, audio_file)\n",
    "    output_audio_path = os.path.join(output_folder, audio_file)\n",
    "    shutil.copy(input_audio_path, output_audio_path)\n",
    "\n",
    "# Function to generate a unique hash for an audio file\n",
    "def generate_audio_hash(audio_data):\n",
    "    return hashlib.sha1(audio_data).hexdigest()\n",
    "\n",
    "# Augment the audio files\n",
    "generated_audios = 0\n",
    "while generated_audios < desired_num_audios:\n",
    "    input_audio_file = random.choice(audio_files)\n",
    "    input_audio_path = os.path.join(input_folder, input_audio_file)\n",
    "\n",
    "    original_audio, sr = librosa.load(input_audio_path, sr=None)\n",
    "\n",
    "    # Random cropping\n",
    "    crop_start = np.random.uniform(0, len(original_audio) - crop_duration * sr)\n",
    "    cropped_audio = original_audio[int(crop_start):int(crop_start + crop_duration * sr)]\n",
    "\n",
    "    # Generate a hash for the augmented audio\n",
    "    audio_hash = generate_audio_hash(cropped_audio)\n",
    "\n",
    "    # Check if the hash is already in the set (duplicate)\n",
    "    if audio_hash not in generated_audio_hashes:\n",
    "        augmented_audio = cropped_audio.copy()\n",
    "        output_audio_path = os.path.join(output_folder, f\"random_cropping_{generated_audios + 1}.wav\")\n",
    "        wavfile.write(output_audio_path, sr, augmented_audio.astype(np.float32))\n",
    "        print(f\"Random cropping audio {generated_audios + 1}/{desired_num_audios} saved: {output_audio_path}\")\n",
    "\n",
    "        # Add the hash to the set\n",
    "        generated_audio_hashes.add(audio_hash)\n",
    "\n",
    "        generated_audios += 1\n",
    "\n",
    "    # Continue to the next iteration if duplicates are found\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Noise injection\n",
    "    noise = np.random.normal(0, noise_level, len(cropped_audio))\n",
    "    augmented_audio = cropped_audio + noise\n",
    "    audio_hash = generate_audio_hash(augmented_audio)\n",
    "    if audio_hash not in generated_audio_hashes:\n",
    "        output_audio_path = os.path.join(output_folder, f\"noise_injection_{generated_audios + 1}.wav\")\n",
    "        wavfile.write(output_audio_path, sr, augmented_audio.astype(np.float32))\n",
    "        print(f\"Noise injection audio {generated_audios + 1}/{desired_num_audios} saved: {output_audio_path}\")\n",
    "        generated_audio_hashes.add(audio_hash)\n",
    "        generated_audios += 1\n",
    "\n",
    "    # Volume adjustment\n",
    "    volume_factor = np.random.uniform(*volume_factor_range)\n",
    "    augmented_audio = cropped_audio * volume_factor\n",
    "    audio_hash = generate_audio_hash(augmented_audio)\n",
    "    if audio_hash not in generated_audio_hashes:\n",
    "        output_audio_path = os.path.join(output_folder, f\"volume_adjustment_{generated_audios + 1}.wav\")\n",
    "        wavfile.write(output_audio_path, sr, augmented_audio.astype(np.float32))\n",
    "        print(f\"Volume adjustment audio {generated_audios + 1}/{desired_num_audios} saved: {output_audio_path}\")\n",
    "        generated_audio_hashes.add(audio_hash)\n",
    "        generated_audios += 1\n",
    "\n",
    "    # Speed perturbation\n",
    "    speed_factor = np.random.uniform(*speed_factor_range)\n",
    "    augmented_audio = librosa.effects.time_stretch(cropped_audio, speed_factor)\n",
    "    audio_hash = generate_audio_hash(augmented_audio)\n",
    "    if audio_hash not in generated_audio_hashes:\n",
    "        output_audio_path = os.path.join(output_folder, f\"speed_perturbation_{generated_audios + 1}.wav\")\n",
    "        wavfile.write(output_audio_path, sr, augmented_audio.astype(np.float32))\n",
    "        print(f\"Speed perturbation audio {generated_audios + 1}/{desired_num_audios} saved: {output_audio_path}\")\n",
    "        generated_audio_hashes.add(audio_hash)\n",
    "        generated_audios += 1\n",
    "\n",
    "    # Pitch variation\n",
    "    pitch_semitones = np.random.uniform(*pitch_semitones_range)\n",
    "    augmented_audio = librosa.effects.pitch_shift(cropped_audio, sr, pitch_semitones)\n",
    "    audio_hash = generate_audio_hash(augmented_audio)\n",
    "    if audio_hash not in generated_audio_hashes:\n",
    "        output_audio_path = os.path.join(output_folder, f\"pitch_variation_{generated_audios + 1}.wav\")\n",
    "        wavfile.write(output_audio_path, sr, augmented_audio.astype(np.float32))\n",
    "        print(f\"Pitch variation audio {generated_audios + 1}/{desired_num_audios} saved: {output_audio_path}\")\n",
    "        generated_audio_hashes.add(audio_hash)\n",
    "        generated_audios += 1\n",
    "\n",
    "    # Continue to the next iteration if duplicates are found\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

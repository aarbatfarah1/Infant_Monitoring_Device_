{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN with MelSpectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "12/12 [==============================] - 8s 509ms/step - loss: 892.9800 - accuracy: 0.7068 - val_loss: 998.9091 - val_accuracy: 0.7826\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 4s 359ms/step - loss: 708.6727 - accuracy: 0.7315 - val_loss: 568.2071 - val_accuracy: 0.7826\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 4s 359ms/step - loss: 154.7180 - accuracy: 0.7014 - val_loss: 110.8661 - val_accuracy: 0.7826\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 4s 356ms/step - loss: 55.5799 - accuracy: 0.7562 - val_loss: 47.3774 - val_accuracy: 0.4565\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 4s 354ms/step - loss: 25.4761 - accuracy: 0.8411 - val_loss: 29.7261 - val_accuracy: 0.7826\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 4s 353ms/step - loss: 9.9314 - accuracy: 0.8849 - val_loss: 14.9647 - val_accuracy: 0.7826\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 4s 356ms/step - loss: 8.6054 - accuracy: 0.8274 - val_loss: 33.6436 - val_accuracy: 0.7826\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 4s 354ms/step - loss: 1.7748 - accuracy: 0.9151 - val_loss: 13.6472 - val_accuracy: 0.7717\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.3124 - accuracy: 0.9726 - val_loss: 9.9834 - val_accuracy: 0.6630\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 4s 356ms/step - loss: 0.1172 - accuracy: 0.9808 - val_loss: 15.3130 - val_accuracy: 0.7826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16fd2d2a8d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Définir le chemin vers votre dataset\n",
    "path_to_your_dataset = 'donateacry_corpus_cleaned_and_updated_data'\n",
    "\n",
    "# Listez les sous-dossiers correspondant à chaque classe\n",
    "subfolders = ['belly_pain', 'burping', 'discomfort', 'hungry', 'tired']\n",
    "\n",
    "# Initialiser des listes pour stocker les chemins des fichiers audio et les étiquettes\n",
    "data = []    # Cette liste stockera les chemins des fichiers audio\n",
    "labels = []  # Cette liste stockera les étiquettes correspondantes (noms de classe)\n",
    "\n",
    "# Parcourez chaque sous-dossier\n",
    "for label, subfolder in enumerate(subfolders):\n",
    "    folder_path = os.path.join(path_to_your_dataset, subfolder)\n",
    "    \n",
    "    # Parcourez chaque fichier audio dans le sous-dossier\n",
    "    for audio_file in os.listdir(folder_path):\n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(folder_path, audio_file)\n",
    "            data.append(audio_path)\n",
    "            labels.append(subfolder)\n",
    "\n",
    "# Convertissez les étiquettes en nombres\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Divisez les données en ensembles de formation et de test (80% formation, 20% test)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fonction pour normaliser les fichiers audio\n",
    "def normalize_audio(audio_path):\n",
    "    audio, _ = librosa.load(audio_path, res_type='kaiser_fast')\n",
    "    normalized_audio = librosa.util.normalize(audio)\n",
    "    return normalized_audio\n",
    "\n",
    "# Normalisez les fichiers audio dans les ensembles de formation et de test\n",
    "train_data = [normalize_audio(audio_path) for audio_path in train_data]\n",
    "test_data = [normalize_audio(audio_path) for audio_path in test_data]\n",
    "# Fonction pour extraire les caractéristiques audio (spectrogrammes)\n",
    "def extract_spectrogram(audio):\n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio, sr=22050, n_mels=128, fmax=8000)\n",
    "    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    return spectrogram_db\n",
    "\n",
    "# Créez des ensembles de formation et de test de spectrogrammes\n",
    "X_train = [extract_spectrogram(audio) for audio in train_data]\n",
    "X_test = [extract_spectrogram(audio) for audio in test_data]\n",
    "\n",
    "# Trouvez la forme minimale des spectrogrammes\n",
    "min_shape = min([spectrogram.shape[1] for spectrogram in X_train + X_test])\n",
    "\n",
    "# Fonction pour remodeler et tronquer les spectrogrammes\n",
    "def reshape_and_truncate(spectrogram, target_shape):\n",
    "    if spectrogram.shape[1] > target_shape:\n",
    "        return spectrogram[:, :target_shape]\n",
    "    else:\n",
    "        return np.pad(spectrogram, ((0, 0), (0, target_shape - spectrogram.shape[1])))\n",
    "\n",
    "# Appliquer reshape_and_truncate à tous les spectrogrammes\n",
    "X_train = [reshape_and_truncate(spectrogram, min_shape) for spectrogram in X_train]\n",
    "X_test = [reshape_and_truncate(spectrogram, min_shape) for spectrogram in X_test]\n",
    "\n",
    "# Convertir les listes en tableaux NumPy\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "\n",
    "# Définissez l'architecture du modèle\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(len(subfolders), activation='softmax'))\n",
    "\n",
    "# Compilez le modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Ajoutez une dimension pour indiquer les canaux (1 pour les niveaux de gris)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "# Entraînez le modèle\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 64ms/step - loss: 15.3130 - accuracy: 0.7826\n",
      "Test Accuracy: 0.782608687877655\n",
      "3/3 [==============================] - 0s 54ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  belly_pain       0.00      0.00      0.00         4\n",
      "     burping       0.00      0.00      0.00         2\n",
      "  discomfort       0.00      0.00      0.00         7\n",
      "      hungry       0.78      1.00      0.88        72\n",
      "       tired       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.78        92\n",
      "   macro avg       0.16      0.20      0.18        92\n",
      "weighted avg       0.61      0.78      0.69        92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Évaluez le modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Faites des prédictions sur l'ensemble de test\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convertissez les prédictions en classes\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Analysez les métriques telles que la précision, le rappel, et la précision\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted_classes, target_names=subfolders))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN with MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 2s 54ms/step - loss: 144.1337 - accuracy: 0.6932 - val_loss: 170.2329 - val_accuracy: 0.7826\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 47.8611 - accuracy: 0.7342 - val_loss: 25.3811 - val_accuracy: 0.6848\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 12.3619 - accuracy: 0.7726 - val_loss: 9.9006 - val_accuracy: 0.7065\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 3.6576 - accuracy: 0.8082 - val_loss: 6.6210 - val_accuracy: 0.7283\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 2.6593 - accuracy: 0.8000 - val_loss: 8.8419 - val_accuracy: 0.7826\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.4739 - accuracy: 0.8027 - val_loss: 4.1072 - val_accuracy: 0.7065\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.0963 - accuracy: 0.8630 - val_loss: 6.3462 - val_accuracy: 0.7826\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.4611 - accuracy: 0.8356 - val_loss: 10.1344 - val_accuracy: 0.7826\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 3.1893 - accuracy: 0.8658 - val_loss: 5.4878 - val_accuracy: 0.4783\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 1.3778 - accuracy: 0.8110 - val_loss: 5.8358 - val_accuracy: 0.7391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16f93182350>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the path to your dataset\n",
    "path_to_your_dataset = 'donateacry_corpus_cleaned_and_updated_data'\n",
    "\n",
    "# List subfolders corresponding to each class\n",
    "subfolders = ['belly_pain', 'burping', 'discomfort', 'hungry', 'tired']\n",
    "\n",
    "# Initialize lists to store file paths and labels\n",
    "data = []    # This list will store the paths of audio files\n",
    "labels = []  # This list will store the corresponding labels (class names)\n",
    "\n",
    "# Iterate through each subfolder\n",
    "for label, subfolder in enumerate(subfolders):\n",
    "    folder_path = os.path.join(path_to_your_dataset, subfolder)\n",
    "    \n",
    "    # Iterate through each audio file in the subfolder\n",
    "    for audio_file in os.listdir(folder_path):\n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(folder_path, audio_file)\n",
    "            data.append(audio_path)\n",
    "            labels.append(subfolder)\n",
    "\n",
    "# Convert labels to numbers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to extract audio features (MFCCs)\n",
    "def extract_mfcc(audio_path):\n",
    "    audio, _ = librosa.load(audio_path, res_type='kaiser_fast')\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=22050, n_mfcc=13)\n",
    "    return mfccs\n",
    "\n",
    "# Create training and testing sets\n",
    "X_train = [extract_mfcc(audio_path) for audio_path in train_data]\n",
    "X_test = [extract_mfcc(audio_path) for audio_path in test_data]\n",
    "\n",
    "# Find the minimum shape of the MFCCs\n",
    "min_shape = min([mfccs.shape[1] for mfccs in X_train + X_test])\n",
    "\n",
    "# Function to reshape and truncate the MFCCs\n",
    "def reshape_and_truncate(mfccs, target_shape):\n",
    "    if mfccs.shape[1] > target_shape:\n",
    "        return mfccs[:, :target_shape]\n",
    "    else:\n",
    "        return np.pad(mfccs, ((0, 0), (0, target_shape - mfccs.shape[1])))\n",
    "\n",
    "# Apply reshape_and_truncate to all MFCCs\n",
    "X_train = [reshape_and_truncate(mfccs, min_shape) for mfccs in X_train]\n",
    "X_test = [reshape_and_truncate(mfccs, min_shape) for mfccs in X_test]\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "# Reshape the input data for the CNN model\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "# Define the CNN model architecture\n",
    "model_cnn_mfcc = models.Sequential()\n",
    "model_cnn_mfcc.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
    "model_cnn_mfcc.add(layers.MaxPooling2D((2, 2)))\n",
    "model_cnn_mfcc.add(layers.Flatten())\n",
    "model_cnn_mfcc.add(layers.Dense(64, activation='relu'))\n",
    "model_cnn_mfcc.add(layers.Dense(len(subfolders), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_cnn_mfcc.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_cnn_mfcc.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 9ms/step - loss: 2.0119 - accuracy: 0.7826\n",
      "Test Accuracy with MFCC: 0.782608687877655\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  belly_pain       0.00      0.00      0.00         4\n",
      "     burping       0.00      0.00      0.00         2\n",
      "  discomfort       0.00      0.00      0.00         7\n",
      "      hungry       0.77      0.94      0.85        72\n",
      "       tired       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.74        92\n",
      "   macro avg       0.15      0.19      0.17        92\n",
      "weighted avg       0.60      0.74      0.67        92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Évaluez le modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy with MFCC: {test_accuracy}\")\n",
    "\n",
    "# Faites des prédictions sur l'ensemble de test\n",
    "predictions = model_cnn_mfcc.predict(X_test)\n",
    "\n",
    "# Convertissez les prédictions en classes\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Analysez les métriques telles que la précision, le rappel, et la précision\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted_classes, target_names=subfolders))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_mfcc.save('cnn_mfcc_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN using MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "46/46 [==============================] - 4s 23ms/step - loss: 0.7972 - accuracy: 0.7681 - val_loss: 0.5867 - val_accuracy: 0.8497\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.4579 - accuracy: 0.8653 - val_loss: 0.4383 - val_accuracy: 0.8607\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.3256 - accuracy: 0.8851 - val_loss: 0.3342 - val_accuracy: 0.8825\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.2478 - accuracy: 0.9234 - val_loss: 0.2695 - val_accuracy: 0.9208\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1959 - accuracy: 0.9425 - val_loss: 0.2242 - val_accuracy: 0.9317\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1534 - accuracy: 0.9576 - val_loss: 0.1761 - val_accuracy: 0.9426\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1145 - accuracy: 0.9720 - val_loss: 0.1371 - val_accuracy: 0.9672\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0835 - accuracy: 0.9884 - val_loss: 0.1027 - val_accuracy: 0.9863\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.0660 - accuracy: 0.9945 - val_loss: 0.0806 - val_accuracy: 0.9863\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.0528 - accuracy: 0.9952 - val_loss: 0.0665 - val_accuracy: 0.9863\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.9863\n",
      "Test Accuracy with mfcc: 0.9863387942314148\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each subfolder\n",
    "for label, subfolder in enumerate(subfolders):\n",
    "    folder_path = os.path.join(path_to_your_dataset, subfolder)\n",
    "    \n",
    "    # Iterate through each audio file in the subfolder\n",
    "    for audio_file in os.listdir(folder_path):\n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(folder_path, audio_file)\n",
    "            data.append(audio_path)\n",
    "            labels.append(subfolder)\n",
    "\n",
    "# Convert labels to numbers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to extract audio features (MFCCs)\n",
    "def extract_features(audio_path):\n",
    "    audio, _ = librosa.load(audio_path, res_type='kaiser_fast')\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=22050, n_mfcc=13)\n",
    "    return mfccs\n",
    "\n",
    "# Create training and testing sets\n",
    "X_train = [extract_features(audio_path) for audio_path in train_data]\n",
    "X_test = [extract_features(audio_path) for audio_path in test_data]\n",
    "\n",
    "# Find the minimum shape of the MFCCs\n",
    "min_shape = min([mfccs.shape[1] for mfccs in X_train + X_test])\n",
    "\n",
    "# Function to reshape and truncate the MFCCs\n",
    "def reshape_and_truncate(mfccs, target_shape):\n",
    "    if mfccs.shape[1] > target_shape:\n",
    "        return mfccs[:, :target_shape]\n",
    "    else:\n",
    "        return np.pad(mfccs, ((0, 0), (0, target_shape - mfccs.shape[1])))\n",
    "\n",
    "# Apply reshape_and_truncate to all MFCCs\n",
    "X_train = [reshape_and_truncate(mfccs, min_shape) for mfccs in X_train]\n",
    "X_test = [reshape_and_truncate(mfccs, min_shape) for mfccs in X_test]\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "# Create the LSTM model\n",
    "model_rnn_mfcc = models.Sequential()\n",
    "model_rnn_mfcc.add(layers.LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_rnn_mfcc.add(layers.Dense(len(subfolders), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_rnn_mfcc.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_rnn_mfcc.fit(X_train, y_train_one_hot, epochs=10, validation_data=(X_test, y_test_one_hot))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model_rnn_mfcc.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"Test Accuracy with mfcc: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN using MelSpectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 4s 133ms/step - loss: 1.5204 - accuracy: 0.7863 - val_loss: 1.1414 - val_accuracy: 0.7826\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.6995 - accuracy: 0.8493 - val_loss: 0.9162 - val_accuracy: 0.7826\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.6452 - accuracy: 0.8493 - val_loss: 0.8248 - val_accuracy: 0.7826\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.6288 - accuracy: 0.8493 - val_loss: 0.8101 - val_accuracy: 0.7826\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.6231 - accuracy: 0.8493 - val_loss: 0.8338 - val_accuracy: 0.7826\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 0.6237 - accuracy: 0.8493 - val_loss: 0.8181 - val_accuracy: 0.7826\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.6248 - accuracy: 0.8493 - val_loss: 0.8139 - val_accuracy: 0.7826\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.6225 - accuracy: 0.8493 - val_loss: 0.8321 - val_accuracy: 0.7826\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.6230 - accuracy: 0.8493 - val_loss: 0.8191 - val_accuracy: 0.7826\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.6315 - accuracy: 0.8493 - val_loss: 0.8288 - val_accuracy: 0.7826\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8288 - accuracy: 0.7826\n",
      "Test Accuracy (RNN with Mel Spectrogram): 0.782608687877655\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the base path of your dataset\n",
    "path_to_your_dataset = 'donateacry_corpus_cleaned_and_updated_data'\n",
    "\n",
    "# List the subfolders corresponding to each class\n",
    "subfolders = ['belly_pain', 'burping', 'discomfort', 'hungry', 'tired']\n",
    "\n",
    "# Initialize lists to store file paths and labels\n",
    "data = []    # This list will store the paths of audio files\n",
    "labels = []  # This list will store the corresponding labels (class names)\n",
    "\n",
    "# Iterate through each subfolder\n",
    "for label, subfolder in enumerate(subfolders):\n",
    "    folder_path = os.path.join(path_to_your_dataset, subfolder)\n",
    "    \n",
    "    # Iterate through each audio file in the subfolder\n",
    "    for audio_file in os.listdir(folder_path):\n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(folder_path, audio_file)\n",
    "            data.append(audio_path)\n",
    "            labels.append(subfolder)\n",
    "\n",
    "# Convert labels to numbers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to extract audio features (Mel Spectrogram)\n",
    "def extract_features(audio_path):\n",
    "    audio, _ = librosa.load(audio_path, res_type='kaiser_fast')\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=22050, n_mels=128, fmax=8000)\n",
    "    return mel_spectrogram\n",
    "\n",
    "# Create training and testing sets\n",
    "X_train = [extract_features(audio_path) for audio_path in train_data]\n",
    "X_test = [extract_features(audio_path) for audio_path in test_data]\n",
    "\n",
    "# Find the minimum shape of the mel spectrograms\n",
    "min_shape = min([mel.shape[1] for mel in X_train + X_test])\n",
    "\n",
    "# Function to reshape and truncate the mel spectrograms\n",
    "def reshape_and_truncate(mel, target_shape):\n",
    "    if mel.shape[1] > target_shape:\n",
    "        return mel[:, :target_shape]\n",
    "    else:\n",
    "        return np.pad(mel, ((0, 0), (0, target_shape - mel.shape[1])))\n",
    "\n",
    "# Apply reshape_and_truncate to all mel spectrograms\n",
    "X_train = [reshape_and_truncate(mel, min_shape) for mel in X_train]\n",
    "X_test = [reshape_and_truncate(mel, min_shape) for mel in X_test]\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_one_hot = to_categorical(train_labels)\n",
    "y_test_one_hot = to_categorical(test_labels)\n",
    "\n",
    "# Create the LSTM model\n",
    "model_rnn_mel = models.Sequential()\n",
    "model_rnn_mel.add(layers.LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_rnn_mel.add(layers.Dense(len(subfolders), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_rnn_mel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_rnn_mel.fit(X_train, y_train_one_hot, epochs=10, validation_data=(X_test, y_test_one_hot))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss_rnn_mel, test_accuracy_rnn_mel = model_rnn_mel.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"Test Accuracy (RNN with Mel Spectrogram): {test_accuracy_rnn_mel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_rnn_mfcc.save('rnn_mfcc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn_mel.save('rnn_mel_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RCNN with MelSpectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 126, 32)           27008     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 63, 32)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 63, 64)            24832     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4032)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                258112    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 310277 (1.18 MB)\n",
      "Trainable params: 310277 (1.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 3s 68ms/step - loss: 35.0497 - accuracy: 0.7671 - val_loss: 41.9586 - val_accuracy: 0.6848\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 10.3649 - accuracy: 0.6795 - val_loss: 17.9533 - val_accuracy: 0.7065\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.8545 - accuracy: 0.8110 - val_loss: 6.1390 - val_accuracy: 0.7283\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 4.1319 - accuracy: 0.8301 - val_loss: 6.7263 - val_accuracy: 0.7283\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 3.9678 - accuracy: 0.7863 - val_loss: 6.7354 - val_accuracy: 0.7174\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7381 - accuracy: 0.7808 - val_loss: 4.2126 - val_accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 4.5986 - accuracy: 0.8027 - val_loss: 3.5112 - val_accuracy: 0.6739\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7224 - accuracy: 0.8000 - val_loss: 1.8426 - val_accuracy: 0.7174\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7223 - accuracy: 0.8137 - val_loss: 3.4024 - val_accuracy: 0.7609\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2841 - accuracy: 0.8356 - val_loss: 2.5888 - val_accuracy: 0.7609\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.5888 - accuracy: 0.7609\n",
      "Test Accuracy (RCNN with Mel Spectrogram): 0.760869562625885\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the base path of your dataset\n",
    "path_to_your_dataset = 'donateacry_corpus_cleaned_and_updated_data'\n",
    "\n",
    "# List the subfolders corresponding to each class\n",
    "subfolders = ['belly_pain', 'burping', 'discomfort', 'hungry', 'tired']\n",
    "\n",
    "# Initialize lists to store file paths and labels\n",
    "data = []    # This list will store the paths of audio files\n",
    "labels = []  # This list will store the corresponding labels (class names)\n",
    "\n",
    "# Iterate through each subfolder\n",
    "for label, subfolder in enumerate(subfolders):\n",
    "    folder_path = os.path.join(path_to_your_dataset, subfolder)\n",
    "    \n",
    "    # Iterate through each audio file in the subfolder\n",
    "    for audio_file in os.listdir(folder_path):\n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(folder_path, audio_file)\n",
    "            data.append(audio_path)\n",
    "            labels.append(subfolder)\n",
    "\n",
    "# Convert labels to numbers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)# Modify these variables according to your data\n",
    "def extract_features(audio_path):\n",
    "    audio, _ = librosa.load(audio_path, res_type='kaiser_fast')\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=22050, n_mels=128, fmax=8000)\n",
    "    return mel_spectrogram\n",
    "\n",
    "# Create training and testing sets\n",
    "X_train = [extract_features(audio_path) for audio_path in train_data]\n",
    "X_test = [extract_features(audio_path) for audio_path in test_data]\n",
    "\n",
    "# Find the minimum shape of the mel spectrograms\n",
    "min_shape = min([mel.shape[1] for mel in X_train + X_test])\n",
    "\n",
    "# Function to reshape and truncate the mel spectrograms\n",
    "def reshape_and_truncate(mel, target_shape):\n",
    "    if mel.shape[1] > target_shape:\n",
    "        return mel[:, :target_shape]\n",
    "    else:\n",
    "        return np.pad(mel, ((0, 0), (0, target_shape - mel.shape[1])))\n",
    "\n",
    "# Apply reshape_and_truncate to all mel spectrograms\n",
    "X_train = [reshape_and_truncate(mel, min_shape) for mel in X_train]\n",
    "X_test = [reshape_and_truncate(mel, min_shape) for mel in X_test]\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_one_hot = to_categorical(train_labels)\n",
    "y_test_one_hot = to_categorical(test_labels)\n",
    "# Create the RCNN model\n",
    "model_rcnn_mel = Sequential()\n",
    "\n",
    "# Convolutional layer\n",
    "model_rcnn_mel.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_rcnn_mel.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# LSTM layer\n",
    "model_rcnn_mel.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "\n",
    "# Flatten layer\n",
    "model_rcnn_mel.add(Flatten())\n",
    "\n",
    "# Dense layers\n",
    "model_rcnn_mel.add(Dense(64, activation='relu'))\n",
    "model_rcnn_mel.add(Dense(len(subfolders), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_rcnn_mel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print a summary of the model architecture\n",
    "model_rcnn_mel.summary()\n",
    "\n",
    "# Train the model\n",
    "model_rcnn_mel.fit(X_train, y_train_one_hot, epochs=10, validation_data=(X_test, y_test_one_hot))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss_rcnn_mel, test_accuracy_rcnn_mel = model_rcnn_mel.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"Test Accuracy (RCNN with Mel Spectrogram): {test_accuracy_rcnn_mel}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RCNN with MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 11, 32)            27008     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 5, 32)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 5, 64)             24832     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 320)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72709 (284.02 KB)\n",
      "Trainable params: 72709 (284.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 2s 42ms/step - loss: 18.6018 - accuracy: 0.5808 - val_loss: 11.1148 - val_accuracy: 0.6739\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.9890 - accuracy: 0.7178 - val_loss: 6.9717 - val_accuracy: 0.6413\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.7273 - accuracy: 0.7370 - val_loss: 3.0781 - val_accuracy: 0.6739\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.9209 - accuracy: 0.7151 - val_loss: 2.1692 - val_accuracy: 0.7065\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.2399 - accuracy: 0.8027 - val_loss: 1.8344 - val_accuracy: 0.7391\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.9143 - accuracy: 0.8000 - val_loss: 1.6185 - val_accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6972 - accuracy: 0.8247 - val_loss: 1.5070 - val_accuracy: 0.7283\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6860 - accuracy: 0.8164 - val_loss: 1.4353 - val_accuracy: 0.7174\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4880 - accuracy: 0.8548 - val_loss: 1.4606 - val_accuracy: 0.7391\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3998 - accuracy: 0.8795 - val_loss: 1.5161 - val_accuracy: 0.6304\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5161 - accuracy: 0.6304\n",
      "Test Accuracy (RCNN with MFCC): 0.6304348111152649\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the base path of your dataset\n",
    "path_to_your_dataset = 'donateacry_corpus_cleaned_and_updated_data'\n",
    "\n",
    "# List the subfolders corresponding to each class\n",
    "subfolders = ['belly_pain', 'burping', 'discomfort', 'hungry', 'tired']\n",
    "\n",
    "# Initialize lists to store file paths and labels\n",
    "data = []    # This list will store the paths of audio files\n",
    "labels = []  # This list will store the corresponding labels (class names)\n",
    "\n",
    "# Iterate through each subfolder\n",
    "for label, subfolder in enumerate(subfolders):\n",
    "    folder_path = os.path.join(path_to_your_dataset, subfolder)\n",
    "    \n",
    "    # Iterate through each audio file in the subfolder\n",
    "    for audio_file in os.listdir(folder_path):\n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(folder_path, audio_file)\n",
    "            data.append(audio_path)\n",
    "            labels.append(subfolder)\n",
    "\n",
    "# Convert labels to numbers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to extract audio features (MFCC)\n",
    "def extract_features(audio_path):\n",
    "    audio, _ = librosa.load(audio_path, res_type='kaiser_fast')\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=22050, n_mfcc=13)\n",
    "    return mfccs\n",
    "\n",
    "# Create training and testing sets\n",
    "X_train = [extract_features(audio_path) for audio_path in train_data]\n",
    "X_test = [extract_features(audio_path) for audio_path in test_data]\n",
    "\n",
    "# Find the minimum shape of the MFCCs\n",
    "min_shape = min([mfccs.shape[1] for mfccs in X_train + X_test])\n",
    "\n",
    "# Function to reshape and truncate the MFCCs\n",
    "def reshape_and_truncate(mfccs, target_shape):\n",
    "    if mfccs.shape[1] > target_shape:\n",
    "        return mfccs[:, :target_shape]\n",
    "    else:\n",
    "        return np.pad(mfccs, ((0, 0), (0, target_shape - mfccs.shape[1])))\n",
    "\n",
    "# Apply reshape_and_truncate to all MFCCs\n",
    "X_train = [reshape_and_truncate(mfccs, min_shape) for mfccs in X_train]\n",
    "X_test = [reshape_and_truncate(mfccs, min_shape) for mfccs in X_test]\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_one_hot = to_categorical(train_labels)\n",
    "y_test_one_hot = to_categorical(test_labels)\n",
    "\n",
    "# Create the RCNN model with MFCC features\n",
    "model_rcnn_mfcc = Sequential()\n",
    "\n",
    "# Convolutional layer\n",
    "model_rcnn_mfcc.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_rcnn_mfcc.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# LSTM layer\n",
    "model_rcnn_mfcc.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "\n",
    "# Flatten layer\n",
    "model_rcnn_mfcc.add(Flatten())\n",
    "\n",
    "# Dense layers\n",
    "model_rcnn_mfcc.add(Dense(64, activation='relu'))\n",
    "model_rcnn_mfcc.add(Dense(len(subfolders), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_rcnn_mfcc.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print a summary of the model architecture\n",
    "model_rcnn_mfcc.summary()\n",
    "\n",
    "# Train the model\n",
    "model_rcnn_mfcc.fit(X_train, y_train_one_hot, epochs=10, validation_data=(X_test, y_test_one_hot))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss_rcnn_mfcc, test_accuracy_rcnn_mfcc = model_rcnn_mfcc.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"Test Accuracy (RCNN with MFCC): {test_accuracy_rcnn_mfcc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_rcnn_mel.save('rcnn_mel_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_rcnn_mfcc.save('rcnn_mfcc_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

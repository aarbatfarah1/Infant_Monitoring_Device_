{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "070c6738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Chaimaa\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Chaimaa\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Chaimaa\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Chaimaa\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Chaimaa\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "12/12 [==============================] - 2s 82ms/step - loss: 38.7474 - accuracy: 0.6877 - val_loss: 4.7249 - val_accuracy: 0.7826\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 1.9092 - accuracy: 0.7534 - val_loss: 1.3174 - val_accuracy: 0.7717\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.9064 - accuracy: 0.8493 - val_loss: 1.0534 - val_accuracy: 0.7826\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.6924 - accuracy: 0.8438 - val_loss: 1.0471 - val_accuracy: 0.7826\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.6781 - accuracy: 0.8493 - val_loss: 1.1275 - val_accuracy: 0.7826\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.6259 - accuracy: 0.8493 - val_loss: 0.9749 - val_accuracy: 0.7826\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.5996 - accuracy: 0.8493 - val_loss: 1.0055 - val_accuracy: 0.7826\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.5908 - accuracy: 0.8493 - val_loss: 0.9028 - val_accuracy: 0.7826\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.5798 - accuracy: 0.8493 - val_loss: 1.0575 - val_accuracy: 0.7826\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.6097 - accuracy: 0.8493 - val_loss: 1.1172 - val_accuracy: 0.7826\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the base path of your dataset\n",
    "path_to_your_dataset = 'donateacry_corpus_cleaned_and_updated_data'\n",
    "\n",
    "# List the subfolders corresponding to each class\n",
    "subfolders = ['belly_pain', 'burping', 'discomfort', 'hungry', 'tired']\n",
    "\n",
    "# Initialize lists to store file paths and labels\n",
    "data = []    # This list will store the paths of audio files\n",
    "labels = []  # This list will store the corresponding labels (class names)\n",
    "\n",
    "# Iterate through each subfolder\n",
    "for label, subfolder in enumerate(subfolders):\n",
    "    folder_path = os.path.join(path_to_your_dataset, subfolder)\n",
    "    \n",
    "    # Iterate through each audio file in the subfolder\n",
    "    for audio_file in os.listdir(folder_path):\n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(folder_path, audio_file)\n",
    "            data.append(audio_path)\n",
    "            labels.append(subfolder)\n",
    "\n",
    "# Convert labels to numbers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to extract audio features (spectrograms)\n",
    "def extract_features(audio_path, target_shape=(128, 128)):\n",
    "    audio, _ = librosa.load(audio_path, res_type='kaiser_fast')\n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio, sr=22050, n_mels=128, fmax=8000)\n",
    "    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    \n",
    "    # Ensure that all spectrograms have the same shape\n",
    "    spectrogram_db_fixed = librosa.util.fix_length(spectrogram_db, size=target_shape[1], axis=1)\n",
    "    \n",
    "    return spectrogram_db_fixed\n",
    "\n",
    "# Create training and testing sets\n",
    "X_train = [extract_features(audio_path) for audio_path in train_data]\n",
    "X_test = [extract_features(audio_path) for audio_path in test_data]\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "# Add a dimension to indicate the channel (1 for grayscale)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))\n",
    "\n",
    "# Convert labels to one-hot format\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "# Data Augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "# Create the CNN model\n",
    "model = models.Sequential()\n",
    "model.add(data_augmentation)  # Add data augmentation\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(len(subfolders), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_one_hot, epochs=10, batch_size=32, validation_data=(X_test, y_test_one_hot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb56268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 18ms/step - loss: 1.1172 - accuracy: 0.7826\n",
      "Accuracy on the test set: 0.782608687877655\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"Accuracy on the test set: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6639addb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: audio_classification_model_cnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: audio_classification_model_cnn\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Chaimaa\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Chaimaa\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model using TensorFlow's save_model\n",
    "model.save(\"audio_classification_model_cnn\")\n",
    "\n",
    "# Load the saved model\n",
    "cnn_model = tf.keras.models.load_model(\"audio_classification_model_cnn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b63662",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479a8b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 2s 20ms/step - loss: 0.8078 - accuracy: 0.7989 - val_loss: 0.7554 - val_accuracy: 0.8087\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5136 - accuracy: 0.8632 - val_loss: 0.6068 - val_accuracy: 0.8361\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8700 - val_loss: 0.5177 - val_accuracy: 0.8470\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8837 - val_loss: 0.4786 - val_accuracy: 0.8525\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2711 - accuracy: 0.8906 - val_loss: 0.4295 - val_accuracy: 0.8525\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2250 - accuracy: 0.9111 - val_loss: 0.4127 - val_accuracy: 0.8579\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1923 - accuracy: 0.9384 - val_loss: 0.3767 - val_accuracy: 0.8852\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1666 - accuracy: 0.9521 - val_loss: 0.3533 - val_accuracy: 0.9016\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1409 - accuracy: 0.9590 - val_loss: 0.3306 - val_accuracy: 0.9071\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1205 - accuracy: 0.9685 - val_loss: 0.3251 - val_accuracy: 0.9126\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.9126\n",
      "Test Accuracy: 0.9125683307647705\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each subfolder\n",
    "for label, subfolder in enumerate(subfolders):\n",
    "    folder_path = os.path.join(path_to_your_dataset, subfolder)\n",
    "    \n",
    "    # Iterate through each audio file in the subfolder\n",
    "    for audio_file in os.listdir(folder_path):\n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(folder_path, audio_file)\n",
    "            data.append(audio_path)\n",
    "            labels.append(subfolder)\n",
    "\n",
    "# Convert labels to numbers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to extract audio features (MFCCs)\n",
    "def extract_features(audio_path):\n",
    "    audio, _ = librosa.load(audio_path, res_type='kaiser_fast')\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=22050, n_mfcc=13)\n",
    "    return mfccs\n",
    "\n",
    "# Create training and testing sets\n",
    "X_train = [extract_features(audio_path) for audio_path in train_data]\n",
    "X_test = [extract_features(audio_path) for audio_path in test_data]\n",
    "\n",
    "# Find the minimum shape of the MFCCs\n",
    "min_shape = min([mfccs.shape[1] for mfccs in X_train + X_test])\n",
    "\n",
    "# Function to reshape and truncate the MFCCs\n",
    "def reshape_and_truncate(mfccs, target_shape):\n",
    "    if mfccs.shape[1] > target_shape:\n",
    "        return mfccs[:, :target_shape]\n",
    "    else:\n",
    "        return np.pad(mfccs, ((0, 0), (0, target_shape - mfccs.shape[1])))\n",
    "\n",
    "# Apply reshape_and_truncate to all MFCCs\n",
    "X_train = [reshape_and_truncate(mfccs, min_shape) for mfccs in X_train]\n",
    "X_test = [reshape_and_truncate(mfccs, min_shape) for mfccs in X_test]\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "# Create the LSTM model\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model2.add(layers.Dense(len(subfolders), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model2.fit(X_train, y_train_one_hot, epochs=10, validation_data=(X_test, y_test_one_hot))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model2.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1272b22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
